# Example 6: Client and Model Initialization

This example demonstrates how to initialize the Google Gen AI client and set up the models for both text generation and embeddings.

```python
# Import the necessary modules
from google import genai

# Initialize the Gen AI client with Vertex AI
client = genai.Client(
    vertexai=True,
    project=PROJECT_ID,
    location=LOCATION,
)

# Set up the Gemini model for text/audio generation
MODEL_ID = "gemini-2.0-flash-live-preview-04-09"
MODEL = f"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{MODEL_ID}"

# Set up the embedding model for document retrieval
text_embedding_model = "text-embedding-005"

# Print model information
print(f"Using generation model: {MODEL_ID}")
print(f"Using embedding model: {text_embedding_model}")
```

## Explanation

This code initializes the AI clients and models that form the core of our RAG system:

1. **Client Initialization**:

   - Creates a `genai.Client` instance configured to use Vertex AI.
   - The `vertexai=True` parameter directs the SDK to use Vertex AI endpoints rather than direct API access.
   - Provides the `project` and `location` parameters to connect to the specific Google Cloud project and region.
   - This client object will be used for all interactions with both the Gemini and embedding models.

2. **Model Selection for Text Generation**:

   - Sets `MODEL_ID` to "gemini-2.0-flash-live-preview-04-09", which is the Gemini 2.0 Flash model.
   - This model offers an optimal balance between:
     - Response quality and accuracy
     - Inference speed (low latency)
     - Cost efficiency
   - The "live-preview" designation indicates this is an evolving model with the latest capabilities.

3. **Fully Qualified Model Name**:

   - Constructs the complete model path using the project ID and location.
   - This full path is required when making API calls to Vertex AI models.
   - The format follows Vertex AI's resource naming convention.

4. **Embedding Model Configuration**:

   - Sets `text_embedding_model` to "text-embedding-005", Google's state-of-the-art embedding model.
   - This model transforms text into high-dimensional vectors (embeddings) that capture semantic meaning.
   - These embeddings will be used for document indexing and similarity-based retrieval.

5. **Strategic Model Choices**:
   - Gemini 2.0 Flash: Selected for its balance of quality and performance in a real-time system.
   - text-embedding-005: Chosen for its superior semantic understanding capabilities.
   - Both models are accessed through Vertex AI for enterprise-grade security, monitoring, and scalability.

These configurations establish the foundation for both the retrieval component (embeddings for semantic search) and generation component (Gemini for answer synthesis) of our RAG system.
