# Example 12: Document Processing and Embedding for RAG

This example demonstrates how to process documents and create embeddings for the retrieval component of our RAG system.

```python
# Define a retry-enabled embedding generation function
@retry(wait=wait_random_exponential(multiplier=1, max=120), stop=stop_after_attempt(4))
def get_embeddings(client, model_name, text):
    """Generate embeddings for input text with retry logic for API quota management.

    Args:
        client: Client for accessing embedding API.
        model_name: Name of the embedding model.
        text: Input text to embed.

    Returns:
        Numpy array containing embeddings if successful, None otherwise.
    """
    try:
        # Generate embeddings
        result = client.models.get_embeddings(
            model=model_name,
            content=text,
        )
        # Return as numpy array for vector operations
        return np.array([result.embedding])

    except Exception as e:
        # Handle quota exceeded errors gracefully
        if "RESOURCE_EXHAUSTED" in str(e):
            print("Quota exceeded for embedding API. Retrying...")
            # Allow retry mechanism to handle this case
            raise e
        # Other errors are printed but function continues
        print(f"Error generating embeddings: {str(e)}")
        return None


# Define function to build document index
def build_index(
    document_paths, embedding_client, embedding_model, chunk_size=750
):
    """Process documents, extract text, create chunks, and generate embeddings.

    Args:
        document_paths: List of paths to PDF documents.
        embedding_client: Client for accessing embedding API.
        embedding_model: Name of the embedding model.
        chunk_size: Size of text chunks in characters.

    Returns:
        DataFrame containing document chunks and their embeddings.
    """
    all_chunks = []

    for doc_path in document_paths:
        try:
            with open(doc_path, "rb") as file:
                pdf_reader = PyPDF2.PdfReader(file)

                for page_num in range(len(pdf_reader.pages)):
                    page = pdf_reader.pages[page_num]
                    page_text = page.extract_text()

                    chunks = [
                        page_text[i : i + chunk_size]
                        for i in range(0, len(page_text), chunk_size)
                    ]

                    for chunk_num, chunk_text in enumerate(chunks):
                        embeddings = get_embeddings(
                            embedding_client, embedding_model, chunk_text
                        )

                        if embeddings is None:
                            print(
                                f"Warning: Could not generate embeddings for chunk {chunk_num} on page {page_num + 1}"
                            )
                            continue

                        chunk_info = {
                            "document_name": doc_path,
                            "page_number": page_num + 1,
                            "page_text": page_text,
                            "chunk_number": chunk_num,
                            "chunk_text": chunk_text,
                            "embeddings": embeddings,
                        }
                        all_chunks.append(chunk_info)

        except Exception as e:
            print(f"Error processing document {doc_path}: {str(e)}")
            continue

    if not all_chunks:
        raise ValueError("No chunks were created from the documents")

    return pd.DataFrame(all_chunks)

# Create document index with embeddings
vector_db_mini_vertex = build_index(
    documents, embedding_client=client, embedding_model=text_embedding_model
)

# Display index information
print(f"Index size: {vector_db_mini_vertex.shape}")

# Preview a sample chunk
print("\nSample chunk content:")
print(vector_db_mini_vertex.loc[0, "chunk_text"][:200] + "...")
```

## Explanation

This code implements the first major component of our RAG pipeline - document processing and embedding:

1. **Embedding Generation**:

   - The `get_embeddings()` function transforms text into numerical vectors using Google's embedding model.
   - These vectors capture the semantic meaning of text, allowing for similarity comparisons.
   - Key features include:
     - Retry logic using the `@retry` decorator to handle API quota limitations
     - Exponential backoff with randomization to prevent request floods
     - Graceful error handling for various failure scenarios
     - Returns a numpy array format for vector operations

2. **Document Processing Pipeline**:

   - The `build_index()` function implements a complete document processing workflow:
     - **Document Loading**: Opens PDF files using PyPDF2 library
     - **Text Extraction**: Pulls raw text content from each PDF page
     - **Chunking Strategy**: Divides text into smaller, manageable chunks of 750 characters
     - **Embedding Generation**: Creates vector representations for each text chunk
     - **Metadata Association**: Links each embedding with document source information
     - **Index Construction**: Organizes everything into a searchable pandas DataFrame

3. **Chunking Considerations**:

   - The default chunk size of 750 characters balances:
     - Having enough context for meaningful understanding
     - Keeping chunks focused on specific topics
     - Managing computational efficiency
   - This approach uses a simple character-based chunking strategy
   - More sophisticated approaches could use:
     - Semantic chunking (dividing by topic)
     - Paragraph or section-based chunking
     - Overlapping chunks for better context preservation

4. **Error Handling and Resilience**:

   - The code includes comprehensive error handling to ensure robustness:
     - Document-level try/except blocks allow processing to continue if one file fails
     - Embedding failures for individual chunks are logged but don't halt the process
     - Empty result validation prevents downstream errors

5. **Technical Implementation Details**:
   - **DataFrame Structure**: Creates a structured data store with columns for:
     - Document name: Source file identification
     - Page number: Location tracking within documents
     - Chunk number: Position within a page
     - Raw text: Original content for generation
     - Embeddings: Vector representations for similarity search
   - **Memory Efficiency**: Stores only necessary metadata and processed content
   - **Scalability**: This approach works well for moderate document collections but would need optimization for very large corpora

This implementation provides the foundation for the retrieval component of our RAG system, creating a searchable index of document content that will be queried based on user questions.
