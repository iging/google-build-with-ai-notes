# Example 10: Interactive Audio Conversation Loop

This example demonstrates how to create a continuous interactive audio conversation experience with Gemini 2.0.

```python
import asyncio
from IPython.display import Audio, display
import numpy as np

async def continuous_audio_generation():
    """Continuously generates audio responses for user queries until explicitly terminated.

    The function creates an interactive loop that:
    1. Prompts the user for text input
    2. Generates an audio response using the Gemini Live API
    3. Repeats until the user types 'q', 'quit', or 'exit'
    """
    print("Interactive Audio Conversation Started")
    print("--------------------------------------")
    print("Ask any question and get audio responses.")
    print("Type 'q', 'quit', or 'exit' to end the conversation.")
    print("Example prompts:")
    print("  - Hello")
    print("  - Who are you?")
    print("  - What's the largest planet in our solar system?")
    print("  - Tell me 3 fun facts about the universe")
    print("--------------------------------------\n")

    # Main conversation loop
    while True:
        # Get user input
        query = input("Your query > ")

        # Check for exit commands
        if any(query.lower() == exit_cmd for exit_cmd in ["q", "quit", "exit"]):
            print("Conversation ended.")
            break

        # Generate and play audio response
        await generate_audio_content(query)
        print("\n--------------------------------------\n")


# Execute the interactive conversation
# Uncomment to run
# await continuous_audio_generation()
```

## Explanation

This code implements an interactive audio conversation system using the Multimodal Live API:

1. **Conversation Loop Structure**:

   - Creates a `while True` infinite loop to maintain the conversation until explicitly terminated.
   - Uses `input()` to collect text queries from the user.
   - Calls the `generate_audio_content()` function (defined in the previous example) to process each query.
   - Provides a clean exit mechanism by checking for specific exit commands ("q", "quit", "exit").

2. **User Experience Design**:

   - Offers clear instructions at the start, explaining how to use the system.
   - Provides example prompts to help users understand what they can ask.
   - Uses a consistent prompt format (`Your query >`) to signal where users should type.
   - Adds visual separators between interactions for improved readability.
   - Shows explicit confirmation when the conversation is ended.

3. **Interaction Model**:

   - Creates a simple turn-based conversation pattern:
     1. User types a query as text
     2. System generates and plays an audio response
     3. System waits for next user input
   - This pattern mimics a basic voice assistant interaction flow.

4. **Technical Characteristics**:

   - **Stateless Design**: Each query is processed independently without maintaining conversation context.
   - **Synchronous Input/Asynchronous Output**: Uses synchronous `input()` for user queries but asynchronous processing for generation.
   - **Text-to-Audio Workflow**: Accepts text input but produces audio output, demonstrating multimodal capabilities.

5. **Practical Applications**:
   - **Voice Assistants**: Foundation for building voice-based question-answering systems.
   - **Accessibility**: Audio responses make information accessible to users with visual impairments.
   - **Hands-Free Interaction**: Useful in scenarios where users can't look at or interact with screens.
   - **Educational Tools**: Can be extended to create interactive learning experiences with spoken explanations.

This implementation demonstrates how relatively simple code can create an engaging audio-based interaction experience. For more sophisticated applications, you might extend this with conversation history tracking, voice input capabilities, or integration with specific knowledge domains.
