# Example 6: Interactive Text-to-Audio Conversation

This example demonstrates how to create an interactive conversation interface where users can type prompts and receive audio responses from Gemini.

```python
import asyncio
import numpy as np
from google import genai
from google.genai.types import LiveConnectConfig, Content, Part
from IPython.display import Audio, Markdown, display

async def interactive_conversation():
    # Initialize the client (assuming it's already been set up)
    # client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)

    # Set the model
    MODEL_ID = "gemini-2.0-flash-live-preview-04-09"

    # Configure the session for audio output
    config = LiveConnectConfig(response_modalities=["AUDIO"])

    # Create the session
    async with client.aio.live.connect(model=MODEL_ID, config=config) as session:
        # Define the send function for user inputs
        async def send() -> bool:
            text_input = input("Input > ")
            # Exit if user types q, quit, or exit
            if text_input.lower() in ("q", "quit", "exit"):
                return False

            # Send the input to the model
            await session.send_client_content(
                turns=Content(role="user", parts=[Part(text=text_input)])
            )
            return True

        # Define the receive function for model responses
        async def receive() -> None:
            audio_data = []

            # Collect audio data from the response
            async for message in session.receive():
                if (
                    message.server_content.model_turn
                    and message.server_content.model_turn.parts
                ):
                    for part in message.server_content.model_turn.parts:
                        if part.inline_data:
                            audio_data.append(
                                np.frombuffer(part.inline_data.data, dtype=np.int16)
                            )

                # When the turn is complete, play the audio
                if message.server_content.turn_complete:
                    display(Markdown("**Response >**"))
                    if audio_data:
                        display(
                            Audio(np.concatenate(audio_data), rate=24000, autoplay=True)
                        )
                    break
            return

        # Main conversation loop
        print("Starting conversation. Type 'q', 'quit', or 'exit' to end the conversation.")
        while True:
            if not await send():  # Get and send user input
                print("Ending conversation.")
                break
            await receive()  # Receive and play audio response

# Run the example (in a notebook, you would use await interactive_conversation())
# asyncio.run(interactive_conversation())
```

## Explanation

This code creates an interactive conversation system with text input and audio output:

1. **Session Configuration**:

   - Establishes a Live API session with audio response modality
   - Uses the default voice settings since no specific voice is specified

2. **Modular Design with Two Key Functions**:

   - `send()`:

     - Prompts the user for input text
     - Checks for exit commands ('q', 'quit', 'exit')
     - Formats and sends the text to the model
     - Returns a boolean indicating whether to continue the conversation

   - `receive()`:
     - Collects audio data chunks from the model's response
     - Checks for the `turn_complete` signal to know when the response is finished
     - Processes the audio data and plays it back with an Audio widget
     - The `break` after playing audio ensures we don't keep waiting for more messages

3. **Main Conversation Loop**:

   - Repeatedly calls `send()` to get user input and send it to the model
   - If `send()` returns `False` (user requested exit), terminates the loop
   - Otherwise, calls `receive()` to collect and play the model's response
   - This creates a turn-taking conversation pattern

4. **Session Context Management**:

   - Uses `async with` to ensure the session is properly closed when the conversation ends
   - Maintains the conversation state within the session throughout the interaction

5. **Usability Features**:
   - Provides clear instructions to the user on how to exit
   - Shows visual indication when a response is coming

This example demonstrates a practical application of the Live API for creating interactive voice assistants or conversational agents where maintaining context across multiple turns is important. While the conversation history is maintained during the session, note that once the session ends, this context is lost.
