# Example 7: Multimodal Prompts

This example demonstrates how to send multimodal prompts combining images and text to Gemini.

```python
from PIL import Image
import requests
from google.genai.types import Part
from IPython.display import Markdown, display

# Method 1: Download and process image locally
image = Image.open(
    requests.get(
        "https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png",
        stream=True,
    ).raw
)

# Generate content using the downloaded image
response = client.models.generate_content(
    model=MODEL_ID,
    contents=[
        image,
        "Write a short and engaging blog post based on this picture.",
    ],
)

print("Response using downloaded image:")
print(response.text)

# Method 2: Reference image directly by URI
response = client.models.generate_content(
    model=MODEL_ID,
    contents=[
        Part.from_uri(
            file_uri="https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png",
            mime_type="image/png",
        ),
        "Write a short and engaging blog post based on this picture.",
    ],
)

print("\nResponse using direct URI reference:")
display(Markdown(response.text))
```

## Explanation

This code demonstrates Gemini's multimodal capabilities by combining image and text inputs:

1. **Image Processing Setup**:

   - Imports necessary libraries: PIL for image handling, requests for HTTP, and Part from the SDK.
   - The example shows two different approaches to working with images in prompts.

2. **Method 1: Local Image Processing**:

   - Downloads an image from Google Cloud Storage using the requests library.
   - Uses `stream=True` for memory efficiency when downloading.
   - Creates a PIL Image object from the downloaded data.
   - Passes this image object directly in the contents list along with a text prompt.

3. **Method 2: Direct URI Reference**:

   - Uses `Part.from_uri()` to reference the image directly by its URL.
   - Specifies the correct MIME type ("image/png") to tell Gemini what kind of file it is.
   - No local downloading or processing is required.
   - This approach works with various file types including images, PDFs, audio, and video.

4. **Multimodal Request Structure**:

   - Both methods use the `contents` parameter as a list containing multiple items.
   - The list can contain a mix of text strings, image objects, and other Part objects.
   - The order of items in the list matters - it represents the sequence presented to the model.

5. **Output Processing**:
   - The model analyzes the image content and follows the text instructions.
   - The response is text-based (a blog post) that's informed by the visual content.
   - The second example displays the response as formatted Markdown for better presentation.

This example demonstrates how Gemini can understand visual content and generate text that meaningfully incorporates information from the image. This capability is useful for content creation, image analysis, and other applications requiring visual understanding.
